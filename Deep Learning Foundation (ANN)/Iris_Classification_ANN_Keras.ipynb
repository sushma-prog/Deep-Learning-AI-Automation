{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "554770c7-93a2-4629-add1-1498ed23ce18",
   "metadata": {
    "id": "554770c7-93a2-4629-add1-1498ed23ce18"
   },
   "source": [
    "---\n",
    "\n",
    "## ğŸ”¹ **Step 1: Deep Learning vs. Machine Learning**\n",
    "\n",
    "This step helps you understand what makes **Deep Learning** special compared to traditional **Machine Learning** â€” so youâ€™ll be clear about when and why to use neural networks.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§  **Theory:**\n",
    "\n",
    "| **Aspect**       | **Machine Learning (ML)**                                      | **Deep Learning (DL)**                                                   |\n",
    "| ---------------- | -------------------------------------------------------------- | ------------------------------------------------------------------------ |\n",
    "| **Input Data**   | Works mostly on **structured/tabular data** (CSV, Excel, etc.) | Works on **both structured and unstructured data** (images, audio, text) |\n",
    "| **Feature Work** | Requires **manual feature engineering**                        | Automatically learns features during training                            |\n",
    "| **Model Types**  | Logistic Regression, Decision Trees, XGBoost, SVM, etc.        | ANN, CNN, RNN, Transformers                                              |\n",
    "| **Scale**        | Works well for **small to medium datasets**                    | Requires **larger data and more computing power**                        |\n",
    "| **Libraries**    | `scikit-learn`, `xgboost`, `lightgbm`                          | `tensorflow`, `keras`, `pytorch`                                         |\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ’¡ **Why Deep Learning?**\n",
    "\n",
    "Unlike ML where we manually tell the model what features matter, Deep Learning **learns from raw data** like pixels or text directly. This is **very useful** when we donâ€™t know which features are important or for complex tasks like:\n",
    "\n",
    "* Image classification ğŸ‘ï¸\n",
    "\n",
    "* Speech recognition ğŸ¤\n",
    "\n",
    "* Language translation ğŸŒ\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“Œ What You Should Remember:\n",
    "\n",
    "| âœ…  | Concept                                    |\n",
    "| -- | ------------------------------------------ |\n",
    "| âœ”ï¸ | DL works best on unstructured data         |\n",
    "| âœ”ï¸ | ANN is a type of DL model                  |\n",
    "| âœ”ï¸ | DL models require more data and compute    |\n",
    "| âœ”ï¸ | We use Keras/TensorFlow to build DL models |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8f69fc-6510-4aed-bb48-e1d4ba8aa738",
   "metadata": {
    "id": "4c8f69fc-6510-4aed-bb48-e1d4ba8aa738"
   },
   "source": [
    "## ğŸ”¹ **Step 2: Understand Neural Network Architecture**\n",
    "\n",
    "An **Artificial Neural Network (ANN)** is inspired by how the human brain works â€” it consists of **neurons** arranged in **layers**. Each neuron receives input, performs a transformation (usually a weighted sum + activation), and passes the result to the next layer.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§  **Architecture Breakdown**\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… 1. **Input Layer**\n",
    "\n",
    "This is where your **features** go in.\n",
    "\n",
    "For example, in the Iris dataset:\n",
    "\n",
    "* You have 4 input features: sepal length, sepal width, petal length, petal width\n",
    "\n",
    "* So the **input layer** has **4 neurons**\n",
    "\n",
    "It doesnâ€™t compute anything â€” it just passes the input to the next layer.\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… 2. **Hidden Layers**\n",
    "\n",
    "These are where **all the learning happens**.\n",
    "\n",
    "Each **neuron** in a hidden layer:\n",
    "\n",
    "* Takes weighted inputs from the previous layer\n",
    "\n",
    "* Applies a **linear function**:\n",
    "\n",
    "  $$\n",
    "  z = w_1x_1 + w_2x_2 + \\dots + w_nx_n + b\n",
    "  $$\n",
    "\n",
    "  where:\n",
    "\n",
    "  * $x_i$ = input features\n",
    "  \n",
    "  * $w_i$ = weights\n",
    "  \n",
    "  * $b$ = bias\n",
    "\n",
    "* Then applies a **non-linear activation function** like:\n",
    "\n",
    "| Activation | Use Case                                               |\n",
    "| ---------- | ------------------------------------------------------ |\n",
    "| `ReLU`     | Most common â€” fast and helps avoid vanishing gradients |\n",
    "| `Sigmoid`  | Squeezes values between 0 and 1 (for binary tasks)     |\n",
    "| `Tanh`     | Scales between -1 and 1 â€” older choice                 |\n",
    "\n",
    "ğŸ§  These **activations** allow your network to learn **non-linear patterns**.\n",
    "\n",
    "You can have **1, 2 or many hidden layers** â€” more layers = deeper network.\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… 3. **Output Layer**\n",
    "\n",
    "This gives the **final prediction**.\n",
    "\n",
    "* **Binary classification (e.g., churn or not):**\n",
    "  \n",
    "  1 neuron + **Sigmoid** activation\n",
    "  \n",
    "  Output between 0 and 1 (probability)\n",
    "\n",
    "* **Multi-class classification (e.g., 3 flower species):**\n",
    "\n",
    "  * 3 neurons (one for each class)\n",
    "  \n",
    "  * Use **Softmax** activation â†’ gives probability for each class\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… 4. **What Happens Internally? (Simple Pipeline)**\n",
    "\n",
    "Letâ€™s say youâ€™re doing binary classification with 4 features:\n",
    "\n",
    "```\n",
    "[4 inputs]\n",
    "     â†“\n",
    "Dense layer (4 â†’ 8 neurons) with ReLU\n",
    "     â†“\n",
    "Dense layer (8 â†’ 4 neurons) with ReLU\n",
    "     â†“\n",
    "Dense layer (4 â†’ 1 neuron) with Sigmoid\n",
    "     â†“\n",
    "Output: 0 or 1 (Churn / No Churn)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“Š **Math Summary:**\n",
    "\n",
    "At every neuron, the following happens:\n",
    "\n",
    "```\n",
    "z = WÂ·X + b\n",
    "\n",
    "a = Activation(z)\n",
    "\n",
    "```\n",
    "\n",
    "Where:\n",
    "\n",
    "* **W** = weight matrix\n",
    "\n",
    "* **X** = input\n",
    "\n",
    "* **b** = bias\n",
    "    \n",
    "* **a** = output of activation function\n",
    "\n",
    "This is called the **forward pass**.\n",
    "\n",
    "During training, we also compute the **error** and update W and b using **backpropagation** (gradient descent) â€” youâ€™ll understand this more in practice.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ¨ **Visual Tool (Highly Recommended)**\n",
    "\n",
    "ğŸŸ¢ Try [https://playground.tensorflow.org](https://playground.tensorflow.org)\n",
    "\n",
    "* Set 1 or 2 hidden layers\n",
    "\n",
    "* Play with ReLU vs Sigmoid\n",
    "\n",
    "* See how **non-linearity changes the output boundary**\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Summary of What You Just Learned\n",
    "\n",
    "| Term             | Meaning                                    |\n",
    "| ---------------- | ------------------------------------------ |\n",
    "| Input Layer      | Feeds raw features to the model            |\n",
    "| Hidden Layers    | Extract patterns via weights + activation  |\n",
    "| Activation Funcs | Add non-linearity (e.g., ReLU, Sigmoid)    |\n",
    "| Output Layer     | Gives final prediction (class/probability) |\n",
    "| Forward Pass     | Computes prediction from input to output   |\n",
    "| Backpropagation  | Updates weights based on error             |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1466dec-414d-4463-9540-9d0860824f4d",
   "metadata": {
    "id": "f1466dec-414d-4463-9540-9d0860824f4d"
   },
   "source": [
    "## ğŸ”¹ Step 3: **Keras Concepts (ANN Basics)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c15d9e8-da08-47a9-bfcc-a417d7c4efeb",
   "metadata": {
    "id": "1c15d9e8-da08-47a9-bfcc-a417d7c4efeb"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential # Sequential is a class inside tensorflow.keras.models submodule that allows us to build a neural network layer by layer.\n",
    "from tensorflow.keras.layers import Dense # Dense is a type of layer where every neuron is connected to every other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "V2jKH3WN3ft8",
   "metadata": {
    "id": "V2jKH3WN3ft8"
   },
   "source": [
    "ğŸ”¸ **What does `Sequential` do?**\n",
    "It creates a model where **you stack layers one after the other** â€” like:\n",
    "\n",
    "```\n",
    "Input â Hidden Layer â Output Layer\n",
    "```\n",
    "\n",
    "No fancy branches, no parallel paths â€” just **a straight line** (which is what most beginner models need!).\n",
    "\n",
    "---\n",
    "\n",
    "ğŸ”¸ **What does `Dense` mean in neural networks?**\n",
    "\n",
    "A `Dense` layer is also called a **fully connected layer** â€” each neuron gets **all the input** from the previous layer.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§  What Are These Used For?\n",
    "\n",
    "* `Sequential()` â†’ Starts your model.\n",
    "\n",
    "* `Dense(units, activation)` â†’ Adds a layer with a certain number of **neurons** and a **function to activate them** (like `ReLU`, `Sigmoid`, etc.).\n",
    "\n",
    "---\n",
    "\n",
    "âœ… So to summarize:\n",
    "\n",
    "| Function / Term | What It Means                                 |\n",
    "| --------------- | --------------------------------------------- |\n",
    "| `Sequential()`  | Starts a simple, layer-by-layer model         |\n",
    "| `Dense()`       | Adds a fully connected layer to the model     |\n",
    "| `compile()`     | Configures model to train (weâ€™ll learn soon!) |\n",
    "| `fit()`         | Starts the training process                   |\n",
    "| `predict()`     | Makes predictions from trained model          |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JFUXao_G83Xr",
   "metadata": {
    "id": "JFUXao_G83Xr"
   },
   "source": [
    "## âœ… **ğŸ”¹ Step 4: Build Your First ANN (Hands-on)**\n",
    "\n",
    "Weâ€™re using the **Iris dataset** â€” itâ€™s a small, easy-to-understand dataset about **flower species**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kDf6e_Ft89oF",
   "metadata": {
    "id": "kDf6e_Ft89oF"
   },
   "source": [
    "### ğŸ“¦ **First: Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "orAOf4PR9FLC",
   "metadata": {
    "id": "orAOf4PR9FLC"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler    # We'll scale/normalize the data to make training easier.\n",
    "from tensorflow.keras.models import Sequential  # Start creating our ANN (step-by-step).\n",
    "from tensorflow.keras.layers import Dense # Add layers (neurons) to the ANN.\n",
    "from tensorflow.keras.utils import to_categorical # Convert output to a one-hot encoded format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GS12-67O-hDp",
   "metadata": {
    "id": "GS12-67O-hDp"
   },
   "source": [
    "### ğŸŒ¸ **1: Load the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hDvuNCat-jS0",
   "metadata": {
    "id": "hDvuNCat-jS0"
   },
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "x = iris.data\n",
    "y = to_categorical(iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LdohQRur-3kU",
   "metadata": {
    "id": "LdohQRur-3kU"
   },
   "source": [
    "* `y = to_categorical(iris.target)`\n",
    "  \n",
    "  â†’ `iris.target` gives us labels like 0, 1, 2 (the flower species).\n",
    "  \n",
    "  â†’ `to_categorical(...)` converts this into **one-hot vectors** like:\n",
    "\n",
    "```\n",
    "0 â†’ [1, 0, 0]\n",
    "1 â†’ [0, 1, 0]\n",
    "2 â†’ [0, 0, 1]\n",
    "```\n",
    "\n",
    "âœ… Why we need this?\n",
    "\n",
    "Because weâ€™re solving a **multi-class classification** problem, not\n",
    "\n",
    "binary â€” categorical_crossentropy does expect the labels in one-hot encoded format. (but if we use the alternative (sparse_categorical_crossentropy) one-hot isnâ€™t needed so there is no need to convert into one hot format or use to_categorical) here we are learning to use loss function categorical_crossentropy and since that loss function works only on one hot vectors so we will convert labels into one hot ones.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FeuXmgfsADoz",
   "metadata": {
    "id": "FeuXmgfsADoz"
   },
   "source": [
    "### ğŸŒ¼ **2: Split and Scale**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ps4Q5kcKAGMg",
   "metadata": {
    "id": "ps4Q5kcKAGMg"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qqWFD5tbA3In",
   "metadata": {
    "id": "qqWFD5tbA3In"
   },
   "source": [
    "* `StandardScaler()`\n",
    "  \n",
    "  â†’ Scales the data so all features have **mean = 0** and **standard deviation = 1**.\n",
    "  \n",
    "  â†’ ANN trains **faster and better** when inputs are scaled properly.\n",
    "\n",
    "* `fit_transform(X_train)`\n",
    "  \n",
    "  â†’ Learns the scaling from training data, then applies it. fit learn scaling from this training data(x_train) and then do transformation on it(i.e apply the scaling you learnt).\n",
    "\n",
    "* `transform(X_test)`\n",
    "  \n",
    "  â†’ Applies the **same scaling** to the test data that's why we only used scaler.transform and not scaler.fit_transform.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yiT_EcWiBtey",
   "metadata": {
    "id": "yiT_EcWiBtey"
   },
   "source": [
    "### ğŸ—ï¸ **Step 3: Build the ANN Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "y5wRiuXMBt_A",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y5wRiuXMBt_A",
    "outputId": "6b2c78ee-243e-4b07-ec6b-03a02adf5d04"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() # Starts an empty ANN.\n",
    "model.add(Dense(8, input_shape=(4,), activation=\"relu\")) # First layer: 8 neurons, each taking 4 inputs (because Iris has 4 features). Uses ReLU as activation.\n",
    "model.add(Dense(3, activation=\"softmax\")) # Output layer: 3 neurons (one for each flower class), uses softmax to give probabilities for each flower class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OhEeiMjYCl3c",
   "metadata": {
    "id": "OhEeiMjYCl3c"
   },
   "source": [
    "ğŸ§  Why `softmax`?\n",
    "\n",
    "Because we want to **predict the class with highest probability**, and\n",
    "\n",
    "softmax converts raw scores into a **probability distribution**.\n",
    "\n",
    "softmax gives probabilities for multiple classes. in this example, for each of 3 flower classes.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7HcpvMijCv2w",
   "metadata": {
    "id": "7HcpvMijCv2w"
   },
   "source": [
    "### âš™ï¸ **4: Compile the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "YhYh6KdpCxiM",
   "metadata": {
    "id": "YhYh6KdpCxiM"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3kNAu2o8E_Fq",
   "metadata": {
    "id": "3kNAu2o8E_Fq"
   },
   "source": [
    "`optimizer='adam'` : Adam is a powerful optimizer that adjusts weights efficiently.\n",
    "\n",
    "`loss='categorical_crossentropy'` : Used when you have **multi-class one-hot labels**.         \n",
    "\n",
    "`metrics=['accuracy']` : We want to **track how many predictions were correct**.        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Jgwpr8ISFbLy",
   "metadata": {
    "id": "Jgwpr8ISFbLy"
   },
   "source": [
    "### ğŸ§ª **5: Train the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "tstc6ISHFhVE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tstc6ISHFhVE",
    "outputId": "553d8af0-6faa-41a9-ed1a-2bb547728df0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5912 - loss: 0.9810\n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5834 - loss: 0.8984 \n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5856 - loss: 0.9145 \n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6026 - loss: 0.8240 \n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6013 - loss: 0.7968 \n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6911 - loss: 0.6805 \n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5816 - loss: 0.7174 \n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6585 - loss: 0.7132 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7206 - loss: 0.6478 \n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8206 - loss: 0.6460 \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7859 - loss: 0.5896 \n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8587 - loss: 0.6229 \n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7868 - loss: 0.5906 \n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8577 - loss: 0.4889 \n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8332 - loss: 0.4989 \n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8500 - loss: 0.4644 \n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8101 - loss: 0.5051 \n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8502 - loss: 0.4478 \n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8674 - loss: 0.4427 \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7767 - loss: 0.4903 \n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8711 - loss: 0.4246 \n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8719 - loss: 0.4145 \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8548 - loss: 0.3973 \n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8458 - loss: 0.4150 \n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8542 - loss: 0.3879 \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8719 - loss: 0.3906 \n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8270 - loss: 0.3857 \n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8484 - loss: 0.3774 \n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8725 - loss: 0.3701 \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8548 - loss: 0.3761 \n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8982 - loss: 0.3201 \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8747 - loss: 0.3583 \n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8858 - loss: 0.3263 \n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8508 - loss: 0.3369 \n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8674 - loss: 0.3282 \n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8720 - loss: 0.3292 \n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9029 - loss: 0.3267 \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9057 - loss: 0.2978 \n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8961 - loss: 0.3003 \n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9244 - loss: 0.2938 \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9096 - loss: 0.2768 \n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9089 - loss: 0.2445 \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8738 - loss: 0.2940 \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9022 - loss: 0.2754 \n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8627 - loss: 0.3224 \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8786 - loss: 0.3101 \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8544 - loss: 0.3329 \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9404 - loss: 0.2439 \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9179 - loss: 0.2758 \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8985 - loss: 0.2824 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7d2fe67390d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=50, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZUtXNVmKGInB",
   "metadata": {
    "id": "ZUtXNVmKGInB"
   },
   "source": [
    "`fit(...)` : This actually **trains the model** on your data.                \n",
    "\n",
    "`epochs=50` : Go through the full dataset **50 times**.                      \n",
    "\n",
    "`batch_size=8` : Break the data into groups of 8 samples at a time for training.\n",
    "\n",
    "ğŸ§  ANN learns slowly by adjusting weights over multiple **epochs**, improving every time.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XwrIi86oIXZg",
   "metadata": {
    "id": "XwrIi86oIXZg"
   },
   "source": [
    "## âœ… **Step 5: Evaluate Model**\n",
    "\n",
    "### ğŸ¯ **Goal:**\n",
    "\n",
    "After training your model, you must check:\n",
    "\n",
    "1. **How well it performs** on **unseen data** (test set).\n",
    "\n",
    "2. **Which classes it predicts correctly** or struggles with.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§ª **1. Evaluate Model Accuracy on Test Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "yJjjRJbwIY_I",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJjjRJbwIY_I",
    "outputId": "5c55875a-722c-48cf-a52e-7b29749510c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - accuracy: 0.8000 - loss: 0.3362\n",
      "Test Accuracy: 0.80\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tj98fq7AL29v",
   "metadata": {
    "id": "tj98fq7AL29v"
   },
   "source": [
    "We pass both x_test and y_test to model.evaluate() so that Keras can:\n",
    "\n",
    "Use x_test data to make predictions output on\n",
    "\n",
    "Use y_test the actual outputs to compare with predictions model made on x_test data\n",
    "\n",
    "Return loss and accuracy.                       \n",
    "\n",
    "Loss is the error between predicted output and actual output.\n",
    "\n",
    "\n",
    "* `model.evaluate(x_test, y_test)`\n",
    "\n",
    "  â†’ Tests the model on **unseen (test)** data and gives:\n",
    "\n",
    "  * **loss** = error on the test data\n",
    "\n",
    "  * **accuracy** = how many predictions were correct (as a %)\n",
    "\n",
    "* `f\"Test Accuracy: {accuracy:.2f}\"`\n",
    "\n",
    "  â†’ Prints test accuracy with 2 decimal places.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m66r--MxNhoe",
   "metadata": {
    "id": "m66r--MxNhoe"
   },
   "source": [
    "### ğŸ” **2. Make Predictions on Test Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "wmr9OWs1NibE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmr9OWs1NibE",
    "outputId": "83577479-200d-4e11-d874-e3f79e1342cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "[[9.99154150e-01 8.24242365e-04 2.15986838e-05]\n",
      " [2.58276034e-02 9.11015689e-01 6.31565899e-02]\n",
      " [3.08712237e-02 4.83526319e-01 4.85602498e-01]\n",
      " [2.37635113e-02 5.29634207e-02 9.23273087e-01]\n",
      " [9.97610986e-01 2.27175606e-03 1.17113806e-04]\n",
      " [9.89514768e-01 1.02897771e-02 1.95316665e-04]\n",
      " [9.98985052e-01 9.76447191e-04 3.86082247e-05]\n",
      " [7.49003962e-02 3.34565163e-01 5.90534508e-01]\n",
      " [1.92115083e-02 1.33187503e-01 8.47601056e-01]\n",
      " [4.12306301e-02 1.92708582e-01 7.66060770e-01]\n",
      " [2.49690320e-02 6.18620992e-01 3.56410086e-01]\n",
      " [3.49252075e-02 2.49300823e-01 7.15773821e-01]\n",
      " [1.16756059e-01 6.92148745e-01 1.91095144e-01]\n",
      " [9.35588405e-03 8.76169860e-01 1.14474244e-01]\n",
      " [9.99324739e-01 6.53223775e-04 2.19976409e-05]\n",
      " [4.40230593e-02 3.97967368e-01 5.58009624e-01]\n",
      " [6.24728836e-02 3.12217295e-01 6.25309706e-01]\n",
      " [9.97175455e-01 2.74445373e-03 8.01090864e-05]\n",
      " [9.97827351e-01 2.10516946e-03 6.74740149e-05]\n",
      " [9.65211466e-02 2.81697661e-01 6.21781170e-01]\n",
      " [1.61211994e-02 3.38253453e-02 9.50053394e-01]\n",
      " [3.31515931e-02 8.21682885e-02 8.84680092e-01]\n",
      " [9.98299360e-01 1.64380902e-03 5.67592397e-05]\n",
      " [8.89052525e-02 2.40730405e-01 6.70364499e-01]\n",
      " [7.70667046e-02 2.33059168e-01 6.89874113e-01]\n",
      " [3.79612036e-02 7.04280198e-01 2.57758647e-01]\n",
      " [9.97426689e-01 2.48065148e-03 9.25813438e-05]\n",
      " [6.74545094e-02 6.87718093e-01 2.44827315e-01]\n",
      " [5.15783252e-03 4.25271429e-02 9.52315032e-01]\n",
      " [5.06827012e-02 7.14135647e-01 2.35181674e-01]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WIgCmFSdNzji",
   "metadata": {
    "id": "WIgCmFSdNzji"
   },
   "source": [
    "#### âš ï¸ Wait! `y_pred` here is **not class labels**, it's probabilities! This gave output like:\n",
    "\n",
    "```\n",
    "[[0.01, 0.94, 0.05],\n",
    " [0.88, 0.08, 0.04],\n",
    " [0.03, 0.01, 0.96]]\n",
    "```\n",
    "\n",
    "So we need to **convert them to actual class labels.** otput should be like this:\n",
    "\n",
    "``[1, 0, 2]\n",
    "``\n",
    "\n",
    "### ğŸŸ¢ Why do we do this?\n",
    "\n",
    "Because evaluation tools (like confusion matrix, accuracy score) expect **class numbers**, not probability vectors. we will plot confusion matrix for evaluation next for that we will need ouput into class numbers since condusion matrix and accuracy score expects class numbers and not probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "iipWrXgAOs5D",
   "metadata": {
    "id": "iipWrXgAOs5D"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_pred_classes = np.argmax(y_pred, axis=1) # Tells NumPy: for each row, find the index of the highest value. argmax = find the index of the maximum value. axis=1 = tells it to check each row of y_pred.\n",
    "y_true = np.argmax(y_test, axis=1) # Our true values (y_test) were one-hot encoded too (like [0,1,0]), so we convert them the same way:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ytsl-8DQmhJ",
   "metadata": {
    "id": "4ytsl-8DQmhJ"
   },
   "source": [
    "ğŸ“Œ Why do we need NumPy here?\n",
    "Because `argmax()` â€” which finds the **index of the largest number** â€” is a NumPy function.\n",
    "\n",
    "---\n",
    "\n",
    "`y_pred_classes = np.argmax(y_pred, axis=1)`\n",
    "\n",
    "Letâ€™s split it:\n",
    "\n",
    "### ğŸ”¹ `y_pred`\n",
    "\n",
    "* This is the model's output â€” for each test sample, it gives **probabilities** for each class.\n",
    "\n",
    "* Example: `[0.1, 0.7, 0.2]` means 70% confidence for class 1.\n",
    "\n",
    "### ğŸ”¹ `np.argmax(y_pred, axis=1)`\n",
    "\n",
    "* `argmax` = find the **index of the maximum value**.\n",
    "\n",
    "* `axis=1` = tells it to check **each row** of `y_pred`.\n",
    "\n",
    "* So this converts:\n",
    "\n",
    "  `[0.1, 0.7, 0.2] â†’ 1`\n",
    "\n",
    "  `[0.9, 0.05, 0.05] â†’ 0`\n",
    "\n",
    "ğŸ§  **Result:** a list of predicted **class numbers** (like `[1, 0, 2, ...]`)\n",
    "\n",
    "### ğŸ”¹ `y_pred_classes = ...`This stores the converted predicted class labels (integers) in a new variable called `y_pred_classes`.\n",
    "\n",
    "---\n",
    "\n",
    "## **for `y_true = np.argmax(y_test, axis=1)`**\n",
    "\n",
    "Same logic â€” but for the **true labels**.\n",
    "\n",
    "* `y_test` is one-hot encoded (looks like `[0, 1, 0]`).\n",
    "* We need to convert it back to class numbers (like `1`) so we can compare.\n",
    "\n",
    "So:\n",
    "\n",
    "```python\n",
    "[1, 0, 0] â†’ 0  \n",
    "[0, 1, 0] â†’ 1  \n",
    "[0, 0, 1] â†’ 2\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OGAgFzqJS1sz",
   "metadata": {
    "id": "OGAgFzqJS1sz"
   },
   "source": [
    "### ğŸ§¾ **3. Confusion Matrix**\n",
    "\n",
    "Letâ€™s now see **how well it performed per class** using a confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "XxzS5cQnS2gM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "XxzS5cQnS2gM",
    "outputId": "5c287f8e-150e-43e3-9d67-1c3596fc2879"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7d2fe4cc70d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "# ConfusionMatrixDisplay(...)\tCreates a graph object based on your matrix.\n",
    "# cm\tThe actual matrix we made in the step above. this need to be passed to parameter name confusion_matrix\n",
    "\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VjYgBddoWwIv",
   "metadata": {
    "id": "VjYgBddoWwIv"
   },
   "source": [
    "### ğŸ” What the Confusion Matrix is Showing:\n",
    "\n",
    "\\| Row = True Label (actual class)\n",
    "\n",
    "\\| Column = Predicted Label (what your model predicted)\n",
    "\n",
    "So for the plot:\n",
    "\n",
    "* **Top-left (9)** = Class `0` was correctly predicted as `0` â†’ âœ… 9 correct predictions\n",
    "\n",
    "* **Middle row**:\n",
    "\n",
    "  * 6 samples of Class `1` were predicted correctly as `1`\n",
    "  * 5 samples of Class `1` were **mistakenly predicted** as `2`\n",
    "\n",
    "* **Bottom row**:\n",
    "\n",
    "  * 9 samples of Class `2` were predicted correctly\n",
    "  * 1 sample was mistakenly predicted as class `1`\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Whatâ€™s good here:\n",
    "\n",
    "* Model is **clearly understanding class `0` very well** (perfect prediction! ğŸ¯)\n",
    "\n",
    "* Class `2` is also predicted well\n",
    "\n",
    "* But Class `1` has some **confusion with Class `2`** â€” this is common in classification problems with similar classes\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Mzj7RpzPXJ09",
   "metadata": {
    "id": "Mzj7RpzPXJ09"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
